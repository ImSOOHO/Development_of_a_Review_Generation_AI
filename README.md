# 음식점 리뷰 생성 AI 구축 및 사용자 기반 모델 최적화
![image](https://github.com/user-attachments/assets/c7abc2f5-a743-4b28-b217-04f44d19783b)

# 1. 프로젝트 개요
- 프로젝트 기간: 2025.02 ~ 현재 (3개월)
- 팀 인원: 2명
- 역할: 팀리더, 전처리, 모델 선택, 모델링, 설문조사 작성, 모델 최적화

# 2. 주제 선정 이유
- 주변 사람들이 생성형 AI의 답변을 맹목적으로 신뢰하는 것을 발견
- 사용자로 하여금 어느 수준의 모델, 어느 수준의 답변이 신뢰도를 확보할 수 있는지 직접 연구해보고자 프로젝트 기획

# 3. 데이터 수집
- 네이버 플레이스: 식당 장르별(한식, 중식, 일식, 양식, 주점, 기타) 1만건씩 수집, 총 6만개의 리뷰 데이터
![image](https://github.com/user-attachments/assets/dd3c22cc-fa84-4925-ae01-5b9cec807000)

# 4. 데이터 분석 수행
## -0. 분석 방향성 및 사용 방법론
- 첫째, 데이터 수집 -> Selenium
- 둘째, 리뷰별 감정 분석 및 텍스트 데이터 전처리 -> BERT 기반 감성분석기, 텍스트 전처리 수행(이모지 제거, 특수문자 제거, 줄임말/비속어 변환 등)
- 셋째, 1차 모델 학습 및 1차 설문조사 -> koGPT-2, Google Forms
- 넷째, 설문조사 분석 및 피드백 기반 모델 최적화(2차 모델) -> 신뢰도 저해 요인 파악 후 Prompt 개선, 추가 Fine-Tuning
- 다섯째, 2차 모델 성능 평가 및 2차 설문조사 -> LLM-as-a-Judge 방식을 이용하여 1차모델과 2차모델 답변 비교(진행중) 후 2차 설문조사 배포(예정)
  
## -1. 리뷰별 감정 분석 및 텍스트 데이터 전처리
- 텍스트 전처리 수행(특수문자 정리, 줄임말/비속어 변환, 이모지 제거, 정규화, 중복문장 제거 등)
- 감정분석 시 한국어 도메인에 유리한 모델들을 탐색
- kcBERT, finBERT 모델들을 이용하여 감정 분석 수행 후 추가 전처리를 통해 리뷰별 감정 라벨링
- 모델 파인튜닝 시, 감정까지 같이 학습
![image](https://github.com/user-attachments/assets/ac1fd603-3867-47db-94fc-44abd5e87f43)

## -2. 1차 모델 학습 및 1차 설문조사
- 한국어 특화 및 파인튜닝 효율이 좋은 모델을 탐색
- koGPT,koBART 등의 모델을 고려 후, koGPT 모델을 최종적으로 선택
- koGPT-3의 경우 로컬 운영시 시간이 오래 걸려 koGPT-2로 파인튜닝 진행
- 평가 지표는 PPL, Distinct-1/2 를 사용
- 파인튜닝 된 모델로부터 나온 결과물을 토대로 설문조사 수행
- 설문조사는 생성형 AI에 대한 기본적인 인식 조사 및 결과물에 대한 신뢰도/신뢰도 저해 요인 파악 관련 질문으로 구성
- 설문지법을 이용하여 설문지 작성
![image](https://github.com/user-attachments/assets/8a9fbde1-a3af-40c3-a23d-f91c373f8367)

## -3. 설문조사 분석 및 피드백 기반 모델 최적화(2차 모델)
- 설문조사 결과, 문장구조의 어색함이 가장 큰 신뢰도 저해요인으로 드러남(전체 중 약 32.8%)
- Prompt 개선 및 출력구조 개선을 통해 문장 구조 개선
- 품질이 좋은 리뷰를 선정해 2000~3000개 규모의 데이터로 다시 Fine-Tuning 진행

## -4. 2차 모델 성능 평가 및 2차 설문조사
- LLM-as-a-Judge 방식을 이용하여 생성된 리뷰 데이터의 품질을 평가(Open AI 의 GPT 모델 API를 이용)
- LLM-as-a-Judge 참고논문(https://arxiv.org/html/2411.15594v4?utm_source=chatgpt.com)
- 1차 모델의 생성 결과와 2차 모델의 생성 결과를 각각 평가한 후 결과 비교
- 2차 설문조사 수행을 통한 신뢰도 변화 추이 관찰
![image](https://github.com/user-attachments/assets/1bcb5843-274f-4546-a3d3-74c1f63703a9)

# 5. 분석 결과
- 비용 문제상 OpenAI의 GPT-4-Turbo 모델만 사용하여 LLM-AS-A-JUDGE 구현
- 총 4개 지표(각각 1~5점 척도)에 대해 LLM-AS-A-Judge 구현(문법성, 유창성, 일관성, 자연스러운 감정 표현)
- 실행 결과 1차 모델에 비해 2차 모델의 리뷰가 평균 3점이상 높았음
- 특히 목표했던 문법성 부분에서 가장 큰 개선이 이루어짐
![image](https://github.com/user-attachments/assets/b57005e6-7d96-4106-af37-0e144aedde32)
![image](https://github.com/user-attachments/assets/cea3a568-4e7f-40e5-b6a8-21e0f8694e7b)

- 2차 설문조사의 표본수는 32명, 1차 설문조사 표본인 68명 보다 적으나 비용 문제상 진행
- 2차 설문조사의 모델 신뢰도는 약 60.31%, 1차 설문조사 모델 신뢰도는 약 44.59%
- 2차 모델이 1차 모델보다 약 15%p 높은 신뢰도 기록
<img src="https://github.com/user-attachments/assets/35eca2b6-c99d-4cc6-9cc4-c316d13cd80d" width="700"/>
