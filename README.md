# 음식점 리뷰 생성 AI 구축 및 사용자 기반 모델 최적화
![image](https://github.com/user-attachments/assets/c74072b6-059d-4686-8b5d-934dd4e08e01)



# 1. 프로젝트 개요
- 프로젝트 기간: 2025.02 ~ 2025.05 (4개월)
- 팀 인원: 2명
- 역할: 팀리더, 전처리, 모델 선택, 모델링, 설문조사 작성, 모델 최적화

# 2. 주제 선정 이유
- 주변 사람들이 생성형 AI의 답변을 맹목적으로 신뢰하는 것을 발견
- 할루시네이션 현상으로 인해 사실이 아님에도 그럴듯하게 말함으로써 사람들이 해당 정보가 Fact인줄 알고 사용
- 그렇다면 어느 정도의 문체, 어느 정도의 모델 수준이 정보의 참/거짓을 떠나서 사용자의 신뢰를 받을 수 있는지 직접 검증해보고자 프로젝트를 기획
- 해당 프로젝트의 목표는 정보의 참/거짓 여부를 떠나서 LLM의 모델 구조 및 파라미터 정도에 따른 출력값의 사용자 기반 신뢰도를 확인해보는 것

# 3. 데이터 수집
- 네이버 플레이스: 식당 장르별(한식, 중식, 일식, 양식, 주점, 기타) 1만건씩 수집, 총 6만개의 리뷰 데이터
![image](https://github.com/user-attachments/assets/dd3c22cc-fa84-4925-ae01-5b9cec807000)

# 4. 데이터 분석 수행
## -0. 분석 방향성 및 사용 방법론
- 첫째, 데이터 수집 -> Selenium
- 둘째, 리뷰별 감정 분석 및 텍스트 데이터 전처리 -> BERT 기반 감성분석기, 텍스트 전처리 수행(이모지 제거, 특수문자 제거, 줄임말/비속어 변환 등)
- 셋째, 1차 모델 학습 및 1차 설문조사 -> koGPT-2, Google Forms
- 넷째, 설문조사 분석 및 피드백 기반 모델 최적화(2차 모델) -> 신뢰도 저해 요인 파악 후 Prompt 개선, 추가 Fine-Tuning
- 다섯째, 2차 모델 성능 평가 및 2차 설문조사 -> LLM-as-a-Judge 방식을 이용하여 1차모델과 2차모델의 출력값을 정량 평가 후 2차 설문조사 배포
  
## -1. 리뷰별 감정 분석 및 텍스트 데이터 전처리
- 텍스트 전처리 수행(특수문자 정리, 줄임말/비속어 변환, 이모지 제거, 정규화, 중복문장 제거 등)
- 감정분석 시 한국어 도메인에 유리한 모델들을 탐색
- kcBERT, finBERT 모델들을 이용하여 감정 분석 수행 후 추가 전처리를 통해 리뷰별 감정 라벨링(긍/부정 2-Class)
- 모델 파인튜닝 시, 감정토큰까지 같이 학습(ex -> [긍정] 양넘이 맛있고 분위기가 좋아요)
![image](https://github.com/user-attachments/assets/ac1fd603-3867-47db-94fc-44abd5e87f43)

## -2. 1차 모델 학습 및 1차 설문조사
- 한국어 특화 및 파인튜닝 효율이 좋은 모델을 탐색
- koGPT,koBART 등의 모델을 고려 후, koGPT 모델을 최종적으로 선택
- koGPT-3의 경우 로컬에서 돌리기엔 리소스적인 문제가 있어 koGPT-2로 파인튜닝을 진행(1차 모델)
- 평가 지표는 PPL, Distinct-1/2 를 사용(문법구조, 다양성 지표로써 사용)
- 파인튜닝 된 모델로부터 나온 결과물을 토대로 설문조사 수행
- 설문조사는 생성형 AI에 대한 기본적인 인식 조사 및 결과물에 대한 신뢰 여부/신뢰도 저해 요인 파악 관련 질문으로 구성
- 설문지법을 이용하여 Google Form 형태의 설문지 작성
![image](https://github.com/user-attachments/assets/8a9fbde1-a3af-40c3-a23d-f91c373f8367)

## -3. 설문조사 분석 및 피드백 기반 모델 최적화(2차 모델)
- 설문조사 결과, '문장구조'의 어색함이 가장 큰 신뢰도 저해요인으로 드러남(전체 중 약 32.8%)
- Prompt 개선 및 출력구조 개선을 통해 출력 문장의 구조 개선
- 품질이 좋은 리뷰를 선정해 3000개 규모의 데이터로 다시 Fine-Tuning 진행(2차 모델)

## -4. 2차 모델 성능 평가 및 2차 설문조사
- LLM-as-a-Judge 방식을 이용하여 1차 모델과 2차모델의 출력값을 정량적으로 비교(Open AI 의 GPT-4-Turbo 모델 API를 이용)
- LLM-as-a-Judge 참고논문(https://arxiv.org/html/2411.15594v4?utm_source=chatgpt.com)
![image](https://github.com/user-attachments/assets/1bcb5843-274f-4546-a3d3-74c1f63703a9)
- 1차 모델 출력값 100개, 2차 모델 출력값 100개, 총 200개의 리뷰에 대해서 LLM-as-a-Judge 방법론을 이용한 정량적 평가 수행
- 총 네개 지표(문법성, 유창성, 일관성, 감정 표현의 자연스러움)에 대해 각 1~5점 척도로 평가(20점 만점 기준)
- 2차 모델의 출력값이 1차 모델에 비해 평균적으로 3점 이상 높았고, '문법성' 점수에서 가장 큰 차이를 보여줌
- 가장 큰 신뢰도 저해 요인이었던 '문법성' 요소에서 개선이 이루어졌다고 판단 후 2차 설문조사 진행
<img src="https://github.com/user-attachments/assets/b57005e6-7d96-4106-af37-0e144aedde32" width="700"/>
<img src="https://github.com/user-attachments/assets/cea3a568-4e7f-40e5-b6a8-21e0f8694e7b" width="700"/>

# 5. 분석 결과
- 2차 설문조사의 표본수는 32명, 1차 설문조사 표본인 68명 보다 적었으나 비용 문제상 진행
- 2차 설문조사의 모델 신뢰도는 약 60.31%, 1차 설문조사 모델 신뢰도는 약 44.59%
- 2차 모델이 1차 모델보다 약 15%p 높은 신뢰도 기록
<img src="https://github.com/user-attachments/assets/35eca2b6-c99d-4cc6-9cc4-c316d13cd80d" width="700"/>

# 6. 회고
- 2차 모델이 1차 모델에 비해서 높은 신뢰도를 보여주고, LLM-AS-A-Judge 방법론을 적용하였을 때도 나은 결과를 보여줬지만 상용가능한 정도는 아님
- 아직도 모델 출력에 대해서 매끄러운 문장만 나오는 것은 아님
- koGPT-2 모델의 한계인지 전처리 및 학습 구조의 문제인지는 따져봐야 할듯
- 언어 모델 학습시 처음부터 대량의 데이터를 학습시키기 보다는 적당한 규모로 실험을 진행하며 성능을 확인할 것
- BERT, GPT 등의 사전학습된 모델을 사용할 경우 학습 도메인 데이터가 어떻게 구성되어 있는지 긴밀하게 확인할 것(HuggingFace 에서 확인)
